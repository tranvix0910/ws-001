[
{
	"uri": "//localhost:1313/",
	"title": "DevSecOps Pipeline",
	"tags": [],
	"description": "",
	"content": "Implementing the DevSecOps Pipeline Overview In this workshop, you will learn the basics of the DevSecOps process — the integration of development (Dev), operations (Ops), and security (Sec) to build a comprehensive and secure CI/CD pipeline. The workshop will guide you through using tools such as GitLab CI/CD, Docker, Portus, and k6 to implement effective DevSecOps solutions on both On-Premise and AWS Cloud infrastructures.\nNội dung Introduction Setting Up the Project Setting Up the CI/CD Pipeline Deploying the Project on Kubernetes (Updating) GitOps (Updating) "
},
{
	"uri": "//localhost:1313/1-introduce/1.1-implementationprocess/",
	"title": "DevSecOps Process",
	"tags": [],
	"description": "",
	"content": "DevSecOps Process Structure The DevSecOps process is a series of automated processes and tools that help build, test, and deliver applications in production environments while securing them at every stage. Typically, companies have three main environments for project deployment: Dev, Staging, and Production. Larger companies may have additional environments such as UAT, Sandbox.\nDev (Development Phase) SAST (Static Application Security Testing): This is the first step in the development phase. SAST analyzes the application\u0026rsquo;s source code to detect potential security vulnerabilities. This check is performed without running the program, helping to identify security issues early in the development process. SCA (Software Composition Analysis): After SAST, SCA is performed to check third-party software components (such as libraries and open-source packages) used in the project. SCA helps detect known security vulnerabilities in these components. Build: After security checks, the source code is built into an executable application. This process may include compiling code, creating application packages, and other necessary steps to prepare the application for deployment. Deploy: Once built, the application is deployed to a testing or staging environment for further evaluation. Unit Test: At this stage, unit tests are performed to ensure that each component of the source code functions as required. Repository (Artifact Management Phase) Artifact Registry: After the application has been tested and deployed, it is stored in an artifact registry. This registry holds different versions of the application, making it easier to manage and deploy later. Image Scan: Docker images or other deployment artifacts are scanned for security vulnerabilities. This is a security check for deployment artifacts before they move on to the next stages. Pre-Prod (Pre-Production Phase) Container: The application is deployed as a container in preparation for testing before deployment to the production environment. DAST (Dynamic Application Security Testing): DAST is performed on the running application to detect security vulnerabilities that may only appear when the application is operational. Performance Test: Performance testing is carried out to assess the application\u0026rsquo;s load capacity and performance under various conditions. This ensures that the application can function well when deployed to production. Prod (Production Phase) K8s (Kubernetes): The application is deployed to the production environment, typically on a Kubernetes (K8s) platform for management and operation. Pen Test (Penetration Testing): Penetration testing is performed in the production environment to detect security vulnerabilities that may have been missed in previous stages. Report: Finally, security, performance, and test results are compiled into reports for a comprehensive assessment of the application\u0026rsquo;s status before and after production deployment. "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction to DevSecOps DevSecOps is a method that integrates security testing at every stage of the software development process. This method includes tools and processes that encourage collaboration between developers, security experts, and operations teams to build both efficient and secure software. DevSecOps brings cultural transformation, making security a shared responsibility for everyone involved in software development.\nDevSecOps stands for development, security, and operations. It is an extension of the DevOps methodology. Each term defines the distinct roles and responsibilities of software teams in building applications.\nDevelopment\nDevelopment is the process of planning, coding, building, and testing applications.\nSecurity\nSecurity means introducing security earlier in the software development lifecycle. For example, developers ensure the code is free from security vulnerabilities, and security practitioners further check the software before the company releases it.\nOperations\nThe operations team releases, monitors, and fixes any issues that arise from the software.\nContent DevSecOps Process Gitlab CI/CD DevSecOps Tools "
},
{
	"uri": "//localhost:1313/2-preparation/2.1-setupservers/",
	"title": "Server Setup for the Project",
	"tags": [],
	"description": "",
	"content": "Install Ubuntu Server First, we will use the Ubuntu version 24.04 operating system to install on a virtual machine.\nLink to Ubuntu Server 24.04 ISO file We will create a virtual machine using VMware Workstation, to install the application you can refer to the following link:\nSet up VMware Workstation Pro 17 on Windows 10/11 Proceed to create the virtual machine on VMware Workstation by following these steps:\nSelect the Ubuntu Server ISO file we just downloaded.\nName the virtual machine and choose a folder that you manage.\nDepending on your machine\u0026rsquo;s configuration, you can select the appropriate Processors and Cores, but GitLab requires at least 2 CPU (Processor Cores).\nNext, choose the default configurations.\nAfter the virtual machine is installed successfully, we will boot the virtual machine and configure the Ubuntu Server.\nContinue to choose the default configurations.\nIn the Storage Configuration section, configure the Root ( / ) partition with the remaining available space.\nTick the option to install OpenSSH.\nWait for Ubuntu to be successfully set up and proceed with Reboot.\nAfter the reboot, log in to the server with the username and password you just created. Note the IPv4 upon login, used for SSH into the server. You can use the ip a command to view IPv4 and other server information.\nOpen CMD on Windows to SSH into the server using the IPv4 and Username.\nHowever, when the server is turned off and back on, the IPv4 may change, so we need to set up a static IP for the server. When rebooting, the IP will remain unchanged, making it easier for us to configure.\nSwitch to Root privileges using the sudo -i command for easier configuration.\nEdit the configuration in the 50-cloud-init.yaml file with the command vi /etc/netplan/50-cloud-init.yaml and write the following configuration:\n# This is the network config written by \u0026#39;subiquity\u0026#39; network: ethernets: ens33: dhcp4: no addresses: [192.168.181.100/24] gateway4: 192.168.181.2 nameservers: addresses: [8.8.8.8, 8.8.4.4] version: 2 Save the file and run the following commands:\n$ netplan apply $ reboot The gateway4 line is the NAT Gateway IP. We can get it in VMware Workstation by accessing Edit -\u0026gt; Virtual Network Editor -\u0026gt; NAT Setting.\nAfter successfully configuring the static IP, we will proceed to create a Snapshot and Clone to other servers.\nRight-click on Gitlab Server -\u0026gt; Snapshot -\u0026gt; Take Snapshot and fill in the information.\nThus, we have successfully created a Snapshot, after that, we will proceed to clone the server.\nAccess Snapshot Manager and perform the following steps:\nAfter that, we will configure the servers according to the following table:\nServer Hostname IP Tĩnh Gitlab Server gitlab-server 192.168.181.101 Development Server development-server 192.168.181.102 Build Server build-server 192.168.181.103 "
},
{
	"uri": "//localhost:1313/3-pipeline/3.1-gitlab-runner/",
	"title": "Setting up GitLab Runner",
	"tags": [],
	"description": "",
	"content": "Installing GitLab Runner To ensure that each server can efficiently perform build and deployment tasks, we will install GitLab Runner on both the Development Server and Build Server.\nInstall GitLab Runner using the following commands:\napt update -y\rcurl -L \u0026#34;https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh\u0026#34; | sudo bash\rapt install gitlab-runner Previously, we discussed the different types of GitLab Runners and how they fit into the project’s needs in Section 1.3. When deploying, you can choose the strategy that best suits your project\u0026rsquo;s characteristics.\nIn this workshop, we will focus on deploying a Group Runner, a flexible and powerful option that allows all projects within the group to be handled by the same Runner. This helps optimize resources and ensures consistency in the CI/CD process.\nGitLab Runner has been successfully installed on both servers.\nConfiguring GitLab Runner Navigate to Groups -\u0026gt; Build -\u0026gt; Runners.\nSelect New group runner.\nSet Tags and Create the Runner, ensuring to tick the Run untagged jobs option.\nGitLab will then guide us on how to register the GitLab-Runner with the virtual machine:\nExecute Step 1:\ngitlab-runner register --url http://gitlab.tranvix.vn --token glrt-DneB3yejRa5zd3F5xLKs After successfully registering on both servers, check in GitLab.\nGitLab has now been successfully set up.\n"
},
{
	"uri": "//localhost:1313/3-pipeline/3.2-build-and-push-image/",
	"title": "Build and Push Docker Image",
	"tags": [],
	"description": "",
	"content": "Setting Up Necessary Configurations Before creating the Dockerfile, you need to update the BASE_URL in the frontend configuration to point to the backend server where you will deploy. Specifically, you need to change this value in the frontend configuration file.\nTo do this on GitLab, follow these steps:\nNavigate to the configuration file: In your frontend project on GitLab, go to src/config/utils.js.\nChange the value of BASE_URL to point to the current backend server.\nNext, we will create a new branch.\nTo ensure the stability of the Main branch, create a new branch for making changes. This keeps the Main branch unaffected during development.\nGo to the + icon and select New Branch. We will name and create the branch.\nWe will also adjust some settings to enhance security.\nNavigate to Settings -\u0026gt; Repository. Change the default branch to the newly created one so that when you access the project, the source code of the Develop branch appears first.\nNext, we will protect the branch. Protecting a branch helps safeguard it from unauthorized Push and Merge actions.\nAdd GitLab-Runner User to Docker Group During the pipeline execution, the gitlab-runner user will be used to run the project.\nAdding gitlab-runner to the Docker group allows the user to execute Docker commands like Login, Logout, Build, and Push Image.\nsudo usermod -aG docker gitlab-runner Create Dockerfile Access the Web IDE for easier interaction.\nCreate the Dockerfile for the Frontend:\n##### Dockerfile ##### ## build stage ## FROM node:22-alpine AS build WORKDIR /app COPY . . RUN npm install RUN npm run build ## run stage ## FROM nginx:alpine COPY --from=build /app/build /usr/share/nginx/html EXPOSE 80 CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] Create GitLab CI/CD We will create a .gitlab-ci.yml file.\nThe .gitlab-ci.yml file is a configuration file used in GitLab CI/CD. It defines pipelines, jobs, and stages to automate tasks like building, testing, and deploying code when changes are made in the repository.\nvariables: PROJECT_USER: \u0026#34;wineapp\u0026#34; IMAGE_VERSION: \u0026#34;${PORTUS_URL}/${PROJECT_USER}/${CI_PROJECT_NAME}:${CI_COMMIT_TAG}_${CI_COMMIT_SHORT_SHA}\u0026#34; stages: - build - push build: stage: build variables: GIT_STRATEGY: clone before_script: - docker login -u ${PORTUS_USER} -p ${PORTUS_PASSWORD} ${PORTUS_URL} script: - docker build -t ${IMAGE_VERSION} . after_script: - docker logout ${PORTUS_URL} tags: - wineapp-build-shell only: - tags push: stage: push variables: GIT_STRATEGY: none before_script: - docker login -u ${PORTUS_USER} -p ${PORTUS_PASSWORD} ${PORTUS_URL} script: - docker push ${IMAGE_VERSION} after_script: - docker logout ${PORTUS_URL} tags: - wineapp-build-shell only: - tags The GitLab CI/CD configuration file is written in YAML.\nBefore explaining the configuration file in detail, let’s explore Variables in GitLab CI/CD.\nThere are two main types of variables:\nPredefined Variables:\nAutomatically provided by GitLab in each pipeline.\nExamples:\nCI_COMMIT_SHA: SHA of the current commit. CI_JOB_ID: ID of the current job. CI_PROJECT_NAME: Name of the project. CI_COMMIT_REF_NAME: Branch or tag name of the current commit. CI_PIPELINE_ID: ID of the pipeline. User-defined Variables:\nThese are defined by the user in the .gitlab-ci.yml file or in the project\u0026rsquo;s settings on GitLab.\nDefined in .gitlab-ci.yml:\nvariables: PROJECT_USER: \u0026#34;wineapp\u0026#34; PORTUS_URL: \u0026#34;https://registry.example.com\u0026#34; Defined in the project settings under Project Settings \u0026gt; CI/CD \u0026gt; Variables:\nCan be set at the project, group, or specific pipeline level.\nSupports features such as protected, masked, and scoped (allowing variables to be limited to certain environments or branches).\nIn the project, the following variables are defined first:\nPROJECT_USER: Used to define the user for deploying the project.\nIMAGE_VERSION: Creates a tag for the Docker image using the following variables:\n${PORTUS_URL}: The URL of the Docker registry (could be Portus).\n${PROJECT_USER}: The user under which the image will be stored.\n${CI_PROJECT_NAME}: The name of the project.\n${CI_COMMIT_TAG}: The tag associated with the commit (could be a version number).\n${CI_COMMIT_SHORT_SHA}: The short version of the commit SHA.\nYou can retrieve the value of a variable using ${\u0026lt;Variable\u0026gt;}.\nNext, we will create the Stages for the Pipeline:\nThe pipeline will be defined with two main stages: build and push.\nbuild: The stage where the Docker image is built.\npush: The stage where the built Docker image is pushed to the Docker registry.\nFor the Build Stage, the following steps will be executed:\nGIT_STRATEGY: clone: Specifies that the repository will be cloned (this is the default behavior).\nbefore_script: Commands executed before the main script. This logs into the Docker registry using credentials stored in the ${PORTUS_USER} and ${PORTUS_PASSWORD} environment variables.\nscript: The main part of this stage, building the Docker image with the IMAGE_VERSION tag.\nafter_script: Logs out from the Docker registry after the build process is completed.\ntags: Specifies the runner (wineapp-build-shell) to be used for this job.\nonly: Ensures this job only runs when a Git Tag is pushed.\nNormally, when the code changes, GitLab CI/CD will start the pipeline. However, when specifying only: -tags, the pipeline will run only when a Tag is created.\nFor the Push Stage, it is similar to the Build Stage with a few differences:\nGIT_STRATEGY : none: No need to clone the source code again at this stage, as it was cloned in the previous stage.\nscript: Pushes the built Docker image to the Docker registry.\nCreate Variables After creating the .gitlab-ci.yml file, commit it and add variables by accessing Project Settings \u0026gt; CI/CD \u0026gt; Variables:\nProceed to add the necessary variables defined in the pipeline, except for GitLab\u0026rsquo;s predefined ones.\nProtect variable: Variables will only run on protected branches and tags.\nExpand variable reference: Any $ character in the variable\u0026rsquo;s value will be treated as a reference to another variable.\nExample: PROJECT_NAME is set to myapp.\nPORTUS_URL is set to https://registry.example.com/$PROJECT_NAME.\nThe variables have been added successfully.\nInitialize Pipeline We will proceed to create a Tag:\nSet the Tag name and make sure to select the correct Branch.\nOnce the Tag is created, the pipeline will start.\nJob Build succeeded.\nJob Push succeeded.\nWhen accessing Portus, the repository has been pushed successfully.\n"
},
{
	"uri": "//localhost:1313/1-introduce/1.2-gitlabcicd/",
	"title": "GitLab CI/CD",
	"tags": [],
	"description": "",
	"content": "GitLab GitLab is a comprehensive DevOps platform that integrates various tools to manage the entire software development lifecycle. With GitLab, development teams can easily manage source code, automate testing and deployment processes through Continuous Integration (CI) and Continuous Deployment (CD) features. Additionally, GitLab offers project management tools, progress tracking, and effective collaboration, enhancing both the quality and speed of software development.\nGitLab comes in two main versions: GitLab CE (Community Edition), a free, open-source version with basic features, and GitLab EE (Enterprise Edition), a commercial version offering advanced features and professional technical support.\nCI/CD CI/CD is a method of delivering applications to customers frequently by automating the stages of application development. The core concepts of CI/CD are Continuous Integration, Continuous Deployment, and Continuous Delivery. CI/CD provides a solution for overcoming issues related to integrating and deploying new code during the operation and development of a project.\nCI/CD enables automation and continuous monitoring throughout the software development lifecycle, from integration and testing to distribution and deployment.\nThis process is part of the DevOps and DevSecOps workflow:\nGitLab CI/CD GitLab CI/CD (Continuous Integration and Continuous Deployment/Delivery) is part of GitLab, an open-source DevOps platform that provides tools to manage the entire software development lifecycle. GitLab CI/CD automates the process of building, testing, and deploying source code, improving software quality and work efficiency.\nKey components of GitLab CI/CD:\nPipeline: A set of jobs executed in a defined order. Each pipeline can have multiple stages, and each stage can have multiple jobs.\nJob: A specific unit of work, such as compiling code, running tests, or deploying applications. Jobs within the same stage are executed in parallel, while stages are executed sequentially.\nRunner: Agents responsible for executing jobs. GitLab Runner can be installed on private servers or use runners provided by GitLab.\n.gitlab-ci.yml: A configuration file stored in your repository. This file defines the pipelines, stages, and jobs to be executed. It is where you define the CI/CD logic for your project.\nIn this workshop, we will proceed with self-hosting GitLab to deploy a project securely, ensuring full control of GitLab in an enterprise environment suited to real-world needs.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.2-containerregistry/",
	"title": "Private Container Registry - Portus",
	"tags": [],
	"description": "",
	"content": "Install Portus Before setting up the Portus Server, you need to rent a Domain to access Portus through it.\nportus.tranvix.online We will create an EC2 Instance to install Portus.\nTo create an instance, you need to have an AWS account and access the EC2 service.\nClick Launch Instance to create an instance.\nSet the name of the server. Choose the operating system, here I select Ubuntu 24.04. Choose a suitable instance type and configure the Key Pair.\nWhen creating a Key Pair, the Private Key will be downloaded to your machine. Be careful not to lose it and do not share it with anyone.\nMake sure to tick Allow HTTPS traffic from the internet.\nThis setting allows anyone to securely access the web server from anywhere through HTTPS. Choose the storage size for the instance. After successfully creating the instance, proceed to access it. Now you have successfully accessed the instance. To install Portus, we need to install some required tools.\nsudo apt install -y docker.io docker-compose certbot net-tools Obtain SSL/TLS certificates with Certbot: Certbot automates the certificate registration process from Let\u0026rsquo;s Encrypt. Just provide the necessary information like Domain and Email.\nRun a Certbot command to get an SSL certificate for a specific domain.\ncertbot certonly --standalone -d portus.tranvix.online --preferred-challenges http --agree-tos -m your-email@gmail.com --keep-until-expiring Saving debug log to /var/log/letsencrypt/letsencrypt.log\r- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\rWould you be willing, once your first certificate is successfully issued, to\rshellare your email address with the Electronic Frontier Foundation, a founding\rpartner of the Let\u0026#39;s Encrypt project and the non-profit organization that\rdevelops Certbot? We\u0026#39;d like to send you email about our work encrypting the web,\rEFF news, campaigns, and ways to support digital freedom.\r- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r(Y)es/(N)o: Y\rAccount registered.\rRequesting a certificate for portus.tranvix.online\rSuccessfully received certificate.\rCertifiate is saved at: /etc/letsencrypt/live/portus.tranvix.online/fullchain.pem \u0026lt;----------------\rKey is saved at: /etc/letsencrypt/live/portus.tranvix.online/privkey.pem \u0026lt;----------------\rThis certificate expires on 2024-10-16.\rThese files will be updated when the certificate renews.\rCertbot has set up a scheduled task to automatically renew this certificate in the background.\r- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\rIf you like Certbot, please consider supporting our work by:\r* Donating to ISRG / Let\u0026#39;s Encrypt: https://letsencrypt.org/donate\r* Donating to EFF: https://eff.org/donate-le\r- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Take note of the paths to the Certificate and Key.\nClone Portus from Github.\ngit clone https://github.com/SUSE/Portus.git Move to the Portus installation directory.\ncd Portus/examples/compose root@ip-172-31-44-184:/tools/portus/Portus/examples/compose# ls -l\rtotal 48\r-rw-r--r-- 1 root root 3715 Jul 18 10:31 README.md\rdrwxr-xr-x 2 root root 4096 Jul 18 10:31 clair\r-rw-r--r-- 1 root root 4345 Jul 18 10:31 docker-compose.clair-ssl.yml\r-rw-r--r-- 1 root root 3540 Jul 18 10:31 docker-compose.clair.yml\r-rw-r--r-- 1 root root 3048 Jul 18 10:31 docker-compose.insecure.yml\r-rw-r--r-- 1 root root 4640 Jul 18 10:31 docker-compose.ldap.yml\r-rw-r--r-- 1 root root 3656 Jul 18 10:31 docker-compose.yml\rdrwxr-xr-x 2 root root 4096 Jul 18 10:31 nginx\rdrwxr-xr-x 2 root root 4096 Jul 18 10:31 registry\rdrwxr-xr-x 2 root root 4096 Jul 18 10:31 secrets Proceed to configure Nginx:\nvi nginx/nginx.conf ssl on; ------\u0026gt; Comment dòng này # Certificates\rssl_certificate /secrets/portus.crt; \u0026lt;-------\rssl_certificate_key /secrets/portus.key; \u0026lt;------- Make sure the paths to the keys are /secrets/portus.crt and /secrets/portus.key.\nCopy and rename the SSL key pair created earlier into these directories.\nroot@ip-172-31-44-184:/tools/portus/compose# cp /etc/letsencrypt/live/portus.tranvix.online/fullchain.pem secrets/portus.crt root@ip-172-31-44-184:/tools/portus/compose# cp /etc/letsencrypt/live/portus.tranvix.online/privkey.pem secrets/portus.key Configure the .env file:\nroot@ip-172-31-44-184:/tools/portus/compose# cat .env MACHINE_FQDN=172.17.0.1 \u0026lt;-------- SECRET_KEY_BASE=b494a25faa8d22e430e843e220e424e10ac84d2ce0e64231f5b636d21251eb6d267adb042ad5884cbff0f3891bcf911bdf8abb3ce719849ccda9a4889249e5c2 PORTUS_PASSWORD=12341234 DATABASE_PASSWORD=portus Change the localhost address to your domain.\nMACHINE_FQDN=portus.tranvix.online SECRET_KEY_BASE=b494a25faa8d22e430e843e220e424e10ac84d2ce0e64231f5b636d21251eb6d267adb042ad5884cbff0f3891bcf911bdf8abb3ce719849ccda9a4889249e5c2 PORTUS_PASSWORD=12341234 DATABASE_PASSWORD=portus Run the docker-compose.clair-ssl.yml file.\ndocker-compose -f docker-compose.clair-ssl.yml up -d Portus has been successfully installed.\nConfigure Portus Using the Public IP from the instance you just created, you can create a record from the domain to point to the Portus server to access the instance via the domain. Proceed to access the domain. Create an Admin User and log in. Create a Registry. Create a User and Group for the project. Configure the created User with Admin rights. Create a Group. You have successfully created a User and Group.\nThus, we have successfully created and set up a Private Registry with Portus.\n"
},
{
	"uri": "//localhost:1313/2-preparation/",
	"title": "Setting Up the Project",
	"tags": [],
	"description": "",
	"content": "Overview In this workshop, we will deploy a web application using the MERN Stack.\nThe MERN Stack consists of four main components: MongoDB, Express.js, React, and Node.js.\nMongoDB – NoSQL database.\nExpressJS – Backend web-application framework for NodeJS.\nReactJS – JavaScript library for building UIs from UI components.\nNodeJS – JavaScript runtime environment, allowing JavaScript to run outside the browser, along with other features.\nWe will deploy the project in an on-premise environment by creating Ubuntu servers through the VMware virtualization platform.\nBelow is the list of necessary servers:\n# OS Version Server Ram CPU Disk IP Username Domain Description 1 Ubuntu 24.04 Gitlab-Server 3Gb 2 20Gb 192.168.181.101 tranvi0910 gitlab.tranvix.vn 2 Ubuntu 24.04 Development Server 2Gb 1 20Gb 192.168.181.102 tranvi0910 3 Ubuntu 24.04 Build Server 2Gb 1 20Gb 192.168.181.103 tranvi0910 GitLab Server:\nThis is the main server used to run GitLab, a platform for source code management and DevOps. GitLab provides features such as project management, source code repository, CI/CD (Continuous Integration/Continuous Deployment).\nIP \u0026amp; Domain: 192.168.181.100, gitlab.tranvix.vn - Allows access to GitLab via the local IP or domain gitlab.tranvix.vn.\nDevelopment Server:\nThis server is used for development environments. Developers can deploy and test code here before pushing it to GitLab or other environments. Build Server:\nThis server is dedicated to building source code from projects. It can be integrated with GitLab to automate the build process when new code is pushed. Using a domain name instead of a specific IP address in the Domain field offers several benefits, particularly in accessing GitLab. A domain name like gitlab.tranvix.vn is easier to remember than an IP address like 192.168.181.101. This makes it easier for users to access GitLab without having to memorize or look up the IP each time.\nContent Thiết lập các Server cho dự án Private Container Registry - Portus Gitlab Server Database Server Source Code Security - Snyk Trivy Security Scan Image Web Application Security Scan Performance Testing - k6 "
},
{
	"uri": "//localhost:1313/1-introduce/1.3-tools/",
	"title": "DevSecOps Tools",
	"tags": [],
	"description": "",
	"content": "Table of Content GitLab Runner Docker Snyk Trivy Scan Image Portus Arachni k6 GitLab Runner GitLab Runner is an open-source tool, written in Go, developed by GitLab for the CI/CD of projects created on GitLab. Users can install their own runners on their server or use the runners provided by GitLab. You just need to create a .gitlab-ci.yml file in the root directory of the project to initialize a CI/CD pipeline and specify which GitLab runner will be used.\nTypes of GitLab Runner Shared Runner\nShared runners are shared among all projects within a GitLab instance and can be used by any project without special configuration.\nAdvantages: Resource-efficient and easy to manage, especially useful for small projects or those not requiring specific resources.\nDeployment: The GitLab instance administrator configures and registers shared runners.\nGroup Runner\nGroup runners are only used by projects within the same GitLab group, allowing control and distribution of resources for related projects.\nAdvantages: Provides better resource usage control across projects within the same group, and is easy to manage and monitor.\nDeployment: The group owner configures and registers group runners via the group settings.\nSpecific Runner\nSpecific runners are assigned to a specific project and only serve that project. This ensures dedicated resources for the project.\nAdvantages: Ensures resources are optimized and more secure for projects requiring specific configurations or high-resource needs.\nDeployment: The project owner configures and registers specific runners via the CI/CD settings of the project.\nEach type of runner has its own advantages and limitations, depending on the needs and scale of the project.\nDocker Docker is an open-source platform that allows the creation, deployment, and management of applications in a containerized environment. With Docker, applications and their dependencies are packaged into containers, ensuring consistency when running across different environments from development to production.\nDocker offers high portability, optimal performance, and simplifies the DevOps process, enabling development and operations teams to work more efficiently. Containers are lighter than virtual machines, start up faster, and can be shared through Docker Hub, which hosts thousands of pre-built container images.\nSteps to Create a Container with Docker Write Dockerfile: Create a Dockerfile that contains the instructions for Docker to know how to build an image for the application, including choosing a base image, installing dependencies, and setting up configurations.\nBuild Docker Image: Use the docker build command to create a Docker image from the Dockerfile.\nRun Container: After creating the image, use the docker run command to create and run a container from that image.\nCheck and Manage Containers: Use commands like docker ps, docker logs, and docker exec to check and manage running containers.\nDocker simplifies the process of developing, deploying, and operating applications using containerization technology. It ensures consistency across different environments and optimizes system resources.\nSnyk Snyk is a security platform for developers that helps detect and fix security vulnerabilities in source code, open-source libraries, containers, and Infrastructure as Code (IaC). Snyk integrates deeply into the software development process, allowing developers to check and repair security issues early during development, before the software is deployed.\nKey Features of Snyk: Open Source Security Scanning: Snyk can scan open-source projects and detect security vulnerabilities in libraries and dependencies used by the project. It provides specific solutions to fix these vulnerabilities.\nContainer Security Scanning: Snyk checks Docker images for security vulnerabilities and suggests optimal fixes, reducing risks when deploying containerized applications.\nSource Code Security Scanning: Snyk can scan your source code to identify potential security vulnerabilities, helping to detect issues early during the coding phase.\nInfrastructure as Code Security Scanning: Snyk can check infrastructure configuration files (such as Terraform, AWS CloudFormation) to ensure they don’t contain security misconfigurations.\nDevOps Integration: Snyk easily integrates with CI/CD tools like Jenkins, GitLab CI, CircleCI, and with IDEs and version control systems like GitHub, GitLab, and Bitbucket.\nSnyk helps developers and DevOps teams proactively secure their software and systems by identifying and fixing security vulnerabilities early throughout the development and deployment process.\nTrivy Scan Image Trivy is an open-source tool for scanning security vulnerabilities and configuration issues in containers, open-source code, and Infrastructure as Code (IaC). Trivy can scan container images to detect security vulnerabilities, protecting applications from potential security risks.\nKey Features of Trivy: Docker Image Scanning: Trivy can scan the layers in Docker images to detect known security vulnerabilities. This ensures that the container images you deploy do not contain serious security issues.\nEasy Integration: Trivy can integrate into the CI/CD process to automatically scan container images before they are deployed, detecting security issues early in the development process.\nSupports Multiple Languages and Systems: Besides containers, Trivy also supports scanning open-source repositories and Infrastructure as Code, including Terraform, CloudFormation, and Kubernetes.\nDetailed and Understandable Results: Trivy provides detailed reports on vulnerabilities, including severity levels (Critical, High, Medium, Low), affected versions, and if available, how to fix the vulnerabilities.\nTrivy is a powerful and easy-to-use security tool that helps developers and DevOps teams protect their applications by detecting security vulnerabilities in container images, open-source code, and Infrastructure as Code.\nPortus Portus is a management interface and security service for self-hosted Docker registries, helping manage and control Docker images within an organization. Developed by SUSE, Portus offers additional features that Docker Registry lacks, such as access control, monitoring, and user management. This ensures that only authorized individuals or services can access and manage container images.\nKey Features of Portus: User and Group Management: Portus allows user and group management within an organization, enabling different access rights based on user roles.\nAccess Control: With Portus, you can set access policies for individual projects or repositories. This protects important images by restricting access.\nDocker Registry Integration: Portus integrates directly with Docker Registry, providing a user-friendly interface to manage Docker images.\nMonitoring and Notifications: Portus provides monitoring capabilities and sends notifications about activities within Docker Registry, making it easy for administrators to track important events, such as image pushes or pulls.\nPortus is a Docker Registry management and security solution that offers extended features like access control, user management, and monitoring, helping organizations manage Docker images safely and efficiently.\nArachni Arachni is an open-source tool used to scan and detect security vulnerabilities in web applications. It can detect many common vulnerabilities such as SQL Injection, XSS, and CSRF.\nArachni offers both a command-line interface (CLI) and a web interface, making it easy to integrate into security workflows.\nThis tool also supports extensions via custom plugins or modules and provides detailed reports in various formats such as HTML, JSON, and XML.\nk6 k6 is an open-source load and performance testing tool, developed by Grafana Labs. With k6, users can write testing scripts in JavaScript and perform performance tests capable of generating thousands of requests per second.\nk6 doesn’t require a graphical user interface, making it ideal for automation and integration into CI/CD systems. It also supports integration with performance monitoring services like Grafana and Prometheus to monitor and analyze test results.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.3-gitlabserver/",
	"title": "Gitlab Server",
	"tags": [],
	"description": "",
	"content": "Install GitLab On the GitLab Server we have created, proceed to install the necessary dependencies.\nsudo apt-get update sudo apt-get install -y curl openssh-server ca-certificates tzdata perl Add the GitLab package repository and install the package.\ncurl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.deb.sh | sudo bash Here we are installing GitLab Self-hosted, which means setting up and running GitLab on your own server instead of using GitLab’s hosted service. This allows you full control over the GitLab environment, including where it’s hosted, how it\u0026rsquo;s configured, and who has access to it.\nNext, install the GitLab package. Use the DNS you want to access the GitLab server.\nsudo EXTERNAL_URL=\u0026#34;http://gitlab.tranvix.vn\u0026#34; apt-get install gitlab-ee GitLab has been successfully installed.\nConfigure GitLab Add a host on Windows.\nOpen Notepad as an administrator.\nOpen the hosts file located at C:\\Windows\\System32\\drivers\\etc\nAt the end of the hosts file, add a new line in the following format:\n\u0026lt;IP address\u0026gt; \u0026lt;domain name\u0026gt; We will add the IP address of the GitLab Server VM and the domain we are using to access GitLab.\n192.168.181.101 gitlab.tranvix.vn Now, access GitLab through the domain http://gitlab.tranvix.vn.\nRetrieve the password by running the following command and log in with the Username root and the retrieved password:\ncat /etc/gitlab/initial_root_password root@gitlab-server:~# cat /etc/gitlab/initial_root_password # WARNING: This value is valid only in the following conditions # 1. If provided manually (either via `GITLAB_ROOT_PASSWORD` environment variable or via `gitlab_rails[\u0026#39;initial_root_password\u0026#39;]` setting in `gitlab.rb`, it was provided before database was seeded for the first time (usually, the first reconfigure run). # 2. Password hasn\u0026#39;t been changed manually, either via UI or via command line. # # If the password shown here doesn\u0026#39;t work, you must reset the admin password following https://docs.gitlab.com/ee/security/reset_user_password.html#reset-your-root-password. Password: frA2Y0Aquj3AS3hLvKowNvUkMyfHD6mU4IdhDnOaSGU= # NOTE: This file will be automatically deleted in the first reconfigure run after 24 hours. Successfully logged in.\nCreating a Group, User, and Project. First, create a Group to house the project. Next, create a User and add the User to the Group.\nGo to Admin and select New User. After successfully creating the User, set a password. Add the User to the Group. Access the Group and create a Project. Select Create blank project. Name the Project and make sure to uncheck Initialize repository with a README if you plan to push an existing repository or create files manually later. Project successfully created. Follow the on-screen instructions to push an existing project to GitLab.\nDownload the project from the links below and move it to the Server Development to push the code to GitLab.\nWineApp Frontend\nWineApp Backend\nIn the folder where the project is stored on your Windows machine, right-click and open Terminal. Run the following command:\nscp .\\* tranvi0910@192.168.181.102:/home/tranvi0910 This command copies all files ./* and directories from the current folder on the local machine to the folder /home/tranvi0910 on the remote server at IP 192.168.181.102, using the tranvi0910 user account.\nCheck the files on the Server Development.\nCreate a new directory to clone the project, then extract the source code we transferred from Windows to the server, and push the code to GitLab.\nmkdir -p /projects/wineapp \u0026amp;\u0026amp; cd /projects/wineapp Add a host on the Server Development to clone the project from GitLab.\nvi /etc/hosts Clone the project.\ngit clone http://gitlab.tranvix.vn/wineapp/wineapp-frontend.git root@development-server:/projects/wineapp# git clone http://gitlab.tranvix.vn/wineapp/wineapp-frontend.git Cloning into \u0026#39;wineapp-frontend\u0026#39;... Username for \u0026#39;http://gitlab.tranvix.vn\u0026#39;: wineappdev Password for \u0026#39;http://wineappdev@gitlab.tranvix.vn\u0026#39;: warning: You appear to have cloned an empty repository. Install the Unzip package.\nsudo apt install unzip Unzip the source code for the frontend.\nunzip wine-website-FE.zip\runzip wine-website-BE.zip After unzipping, you will have two folders. Move the source code from the unzipped folder to the Frontend project we cloned earlier.\ncp -rf wine-website-FE-main/* /projects/wineapp/wineapp-frontend/ Push the code.\ngit add . git commit -m \u0026#39;project(base): add base project\u0026#39; git push Check the project on GitLab. The project has been successfully pushed to GitLab. Follow similar steps for the Backend Project.\n"
},
{
	"uri": "//localhost:1313/3-pipeline/3.3-security-performance/",
	"title": "Security Scan and Performance Test",
	"tags": [],
	"description": "",
	"content": "Code Security Scan Stage After setting up the build and pushing the image, we will add a Stage to scan the Source Code for security.\nsnykscan: stage: snykscan variables: GIT_STRATEGY: clone before_script: - snyk auth ${SNYK_API_TOKEN} script: - snyk test --json | snyk-to-html -do ${SNYKSCAN_FILE}.html || true tags: - wineapp-build-shell artifacts: paths: - ${SNYKSCAN_FILE}.html expire_in: 1 day In GitLab CI/CD, artifacts are files or directories that are saved from a job after that job has finished executing.\nArtifacts are often used to store the results of the build, testing processes, or other important information that you want to keep and use in other jobs in the pipeline.\npaths:\n${SNYKSCAN_FILE}.html Defines the artifact files that the job will save after execution. In this case, the HTML file contains the results of the security scan. expire_in: 1 day\nSets the lifespan of the artifact to 1 day. After this period, the artifact will be deleted. We will proceed to add this Stage to .gitlab-ci.yml.\nNote to create Variables such as SNYKSCAN_FILE and SNYK_API_TOKEN.\nSNYKSCAN_FILE: \u0026#34;SNYK_SECURITY_SCAN_${CI_PROJECT_NAME}_${CI_COMMIT_TAG}_${CI_COMMIT_SHORT_SHA}\u0026#34; We will create a tag, and the pipeline will start.\nAfter successfully running the pipeline, a new stage called Code Security Scan will be added, and there will be a detailed test report file available for download here:\nAlternatively, you can access the Artifacts section:\nAfter downloading, extract the file and check the report in HTML format.\nScan Image Stage The security scan of the image will be performed right after we successfully build the image.\nWe will add a stage to scan the image for vulnerabilities:\ntrivy scan image: stage: trivy scan image variables: GIT_STRATEGY: none script: - docker run --rm -v $(pwd):/wineapp-frontend -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy clean --all - docker run --rm -v $(pwd):/${CI_PROJECT_NAME} -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy image --format template --template \u0026#34;@contrib/html.tpl\u0026#34; --output /${CI_PROJECT_NAME}/${TRIVY_IMAGE_REPORT}.html ${IMAGE_VERSION} tags: - wineapp-build-shell only: - tags artifacts: paths: - ${TRIVYFS_REPORT}.html expire_in: 1 day Create a variable to define the name of the report file:\nTRIVY_IMAGE_REPORT: \u0026#34;TRIVYFS_SCAN_IMAGE_REPORT_${CI_PROJECT_NAME}_${CI_COMMIT_TAG}_${CI_COMMIT_SHORT_SHA}\u0026#34; In this stage, we have two parts, both using the Trivy tool to scan for vulnerabilities in a Docker image.\nPart 1: Clean all Trivy temporary data to prepare for a new scan.\ndocker run --rm: Runs a Docker container and automatically removes it after the task is completed.\n-v $(pwd):/wineapp-frontend: Mounts the current directory ($(pwd)) to the /wineapp-frontend path inside the container.\n-v /var/run/docker.sock:/var/run/docker.sock: Mounts the Docker socket from the host into the container, allowing the container to perform Docker-related operations.\naquasec/trivy clean --all: Uses Trivy\u0026rsquo;s clean command to remove all temporary or old data created during previous scans.\nPart 2: Scan the Docker image for vulnerabilities, generate a report in HTML format, and save it in the artifacts section.\naquasec/trivy image: Uses Trivy\u0026rsquo;s image command to scan the Docker image we just created for vulnerabilities.\n--format template: Specifies the output format as a template.\n--template \u0026quot;@contrib/html.tpl\u0026quot;: Uses the HTML template file (html.tpl) to format the scan results.\n--output /${CI_PROJECT_NAME}/${TRIVY_IMAGE_REPORT}.html: Specifies the path and filename for the HTML report. The report will be saved in the project directory, with the filename depending on the value of ${TRIVY_IMAGE_REPORT}.\nAdd the stage to the configuration file, create a tag, and check the pipeline:\nAfter the pipeline runs successfully, check the Artifacts section to download the report file from the image security scan stage.\nCheck the report file:\nDeploy the Project We have completed the testing and verification steps before deploying the project. In this section, we will deploy the front-end project.\nWe will deploy the project to the development server.\ndeploy: stage: deploy variables: GIT_STRATEGY: none before_script: - docker login -u ${PORTUS_USER} -p ${PORTUS_PASSWORD} ${PORTUS_URL} script: - sudo su ${PROJECT_USER} -c \u0026#34;docker pull ${IMAGE_VERSION}; docker rm -f ${CI_PROJECT_NAME}; docker run --name ${CI_PROJECT_NAME} -dp ${FE_PORT} ${IMAGE_VERSION}\u0026#34; after_script: - docker logout ${PORTUS_URL} tags: - wineapp-dev-shell only: - tags In the tags section, we will set it to wineapp-dev-shell because this is the GitLab-Runner tag configured on the development server.\nWe will create the variable FE_PORT with the value 3000:80, meaning that when you access http://\u0026lt;ip_server_dev\u0026gt;:3000, this request will be forwarded to port 80 of the container, where the application inside the container will handle the request.\nThe deploy job is an automated deployment step in the GitLab CI/CD pipeline.\nIt performs Docker-related operations to pull the Docker image we pushed, stop the current container, and restart the container with the new version of the application.\nEverything is done under a specific user\u0026rsquo;s (PROJECT_USER) permissions to ensure security and role management.\nNote:\nIn the script section, we use the sudo su command to switch users. Normally, when using this command, you would need to enter a password. However, during the pipeline run, there is no way to manually input a password.\nTherefore, to avoid this, we will configure the GitLab Runner user to run the sudo su command without needing to enter a password.\nOn the command line interface, you need to enter the sudo visudo command and provide your password. Then, add the following line to the configuration file to complete the setup:\ngitlab-runner ALL=(ALL) NOPASSWD: /bin/su To save the file, press F2 + Y + Enter.\nMake changes on the development server.\rAfter configuring, we will add the stage to the pipeline and create a tag.\nNow that the pipeline has run successfully, proceed to check at the following address:\n192.168.181.102:3000 192.168.181.102 is the IP of the development server where we deployed the application.\n3000 is the port used to run the application, which was declared when we ran the container.\nThe web has been successfully deployed. We can check the container by running the following command:\ndocker container ps Website Security Scan - Arachni After the deployment step, we will proceed to perform a security test of the web application we just deployed.\nWe will set up Arachni as described in Section 2.7.\nWeb Application Security Scan security scan website: stage: security scan website variables: ARACHNI_USER: \u0026#34;arachni\u0026#34; PATH_TO_ARACHNI_VERSION: \u0026#34;/home/arachni/arachni-1.6.1.3-0.6.1.1/\u0026#34; GIT_STRATEGY: none script: - sudo su ${ARACHNI_USER} -c \u0026#34;cd ${PATH_TO_ARACHNI_VERSION}; bin/arachni --output-verbose --scope-include-subdomains ${ADDRESS_FRONTEND} --report-save-path=/tmp/${ARACHNI_WEBSITE_REPORT}.afr \u0026gt; /dev/null 2\u0026gt;\u0026amp;1\u0026#34; - sudo su ${ARACHNI_USER} -c \u0026#34;cd ${PATH_TO_ARACHNI_VERSION}; bin/arachni_reporter /tmp/${ARACHNI_WEBSITE_REPORT}.afr --reporter=html:outfile=/tmp/${ARACHNI_WEBSITE_REPORT}.html.zip\u0026#34; - sudo chmod 777 /tmp/${ARACHNI_WEBSITE_REPORT}.html.zip - cp /tmp/${ARACHNI_WEBSITE_REPORT}.html.zip . tags: - wineapp-dev-shell artifacts: paths: - ${ARACHNI_WEBSITE_REPORT}.html.zip expire_in: 1 day only: - tags The security scan website job performs a security scan on a website, generates a security report, and saves it as a .zip file so you can download it after the pipeline completes.\nADDRESS_FRONTEND is the address of the website we just deployed.\nARACHNI_WEBSITE_REPORT is the name file report.\nWhen executing the sudo chmod command, you are also required to enter a password, so you need to configure it as shown above.\ngitlab-runner ALL=(ALL) NOPASSWD: /bin/chmod Add a Stage to the Pipeline and create the necessary Variables, then create a tag and check the Pipeline.\nYou will get a Report as follows: Performance Test - k6 To test the performance of the website with k6, we will create a test file written in JavaScript.\nimport http from \u0026#39;k6/http\u0026#39;; import { check, sleep } from \u0026#39;k6\u0026#39;; export let options = { vus: 1, duration: \u0026#39;10s\u0026#39;, }; export default function () { const BASE_URL = `${__ENV.FE_HOST}`; let res = http.get(BASE_URL); check(res, { \u0026#39;homepage status is 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); sleep(1); } Then we will add the test file to the repository containing the code.\nAdd Stage to Pipeline:\nperformance testing: stage: performance testing variables: GIT_STRATEGY: none SCRIPT_PATH: performance_testing_script script: - sudo chmod -R 754 ./${SCRIPT_PATH} - docker run --user ${ID_USER_GITLAB_RUNNER}:${ID_GROUP_GITLAB_RUNNER} --rm -v $(pwd)/${SCRIPT_PATH}:/${SCRIPT_PATH} grafana/k6 run -e FE_HOST=${FE_HOST} --summary-export=/${SCRIPT_PATH}/summary_perf.json /${SCRIPT_PATH}/smoke_test.js - docker run --user ${ID_USER_GITLAB_RUNNER}:${ID_GROUP_GITLAB_RUNNER} --rm -v $(pwd)/${SCRIPT_PATH}:/${SCRIPT_PATH} grafana/k6 run -e FE_HOST=${FE_HOST} /${SCRIPT_PATH}/smoke_test.js - mv ./${SCRIPT_PATH}/summary.html $(pwd)/${K6_PERFORMANCE_TEST_REPORT}.html - cat ./${SCRIPT_PATH}/summary_perf.json | jq -r \u0026#39;[\u0026#34;metric\u0026#34;, \u0026#34;avg\u0026#34;, \u0026#34;min\u0026#34;, \u0026#34;med\u0026#34;, \u0026#34;max\u0026#34;, \u0026#34;p(90)\u0026#34;, \u0026#34;p(95)\u0026#34;], (.metrics | to_entries[] | [.key, .value.avg, .value.min, .value.med, .value.max, .value[\u0026#34;p(90)\u0026#34;], .value[\u0026#34;p(95)\u0026#34;]]) | @csv\u0026#39; \u0026gt; ${K6_PERFORMANCE_TEST_REPORT}.csv after_script: - sudo chown -R gitlab-runner $(pwd) tags: - wineapp-dev-shell artifacts: paths: - ${K6_PERFORMANCE_TEST_REPORT}.html - ${K6_PERFORMANCE_TEST_REPORT}.csv expire_in: 1 day only: - tags The performance testing job in GitLab CI/CD is designed to perform performance testing for the project using the k6 tool.\nThe Docker container is run under the GitLab Runner user via the variables ID_USER_GITLAB_RUNNER and ID_GROUP_GITLAB_RUNNER.\nA Docker container with k6 is started to perform testing based on the smoke_test.js script. The test results are output as a JSON file summary_perf.json. The results are then moved and converted into HTML and CSV files and stored in artifacts.\nAfter the Pipeline runs successfully, you will get a report file in HTML format.\n/\\ |‾‾| /‾‾/ /‾‾/\r/\\ / \\ | |/ / / /\r/ \\/ \\ | ( / ‾‾\\\r/ \\ | |\\ \\ | (‾) |\r/ __________ \\ |__| \\__\\ \\_____/ .io\rexecution: local\rscript: performance_testing_script/smoke_test.js\routput: -\rscenarios: (100.00%) 1 scenario, 1 max VUs, 40s max duration (incl. graceful stop):\r* default: 1 looping VUs for 10s (gracefulStop: 30s)\r✓ homepage status is 200\rchecks.........................: 100.00% ✓ 10 ✗ 0\rdata_received..................: 8.1 kB 808 B/s\rdata_sent......................: 860 B 86 B/s\rhttp_req_blocked...............: avg=240.69µs min=3.15µs med=4.21µs max=2.36ms p(90)=241.93µs p(95)=1.3ms\rhttp_req_connecting............: avg=124.41µs min=0s med=0s max=1.24ms p(90)=124.41µs p(95)=684.3µs\rhttp_req_duration..............: avg=512.44µs min=318.21µs med=491.68µs max=679.04µs p(90)=652.66µs p(95)=665.85µs\r{ expected_response:true }...: avg=512.44µs min=318.21µs med=491.68µs max=679.04µs p(90)=652.66µs p(95)=665.85µs\rhttp_req_failed................: 0.00% ✓ 0 ✗ 10\rhttp_req_receiving.............: avg=90.44µs min=38.49µs med=87.98µs max=129.07µs p(90)=128.62µs p(95)=128.84µs\rhttp_req_sending...............: avg=47.97µs min=15.66µs med=17.02µs max=305.24µs p(90)=64.64µs p(95)=184.94µs\rhttp_req_tls_handshaking.......: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s\rhttp_req_waiting...............: avg=374.02µs min=229.34µs med=365.44µs max=529.58µs p(90)=519.81µs p(95)=524.69µs\rhttp_reqs......................: 10 0.998173/s\riteration_duration.............: avg=1s min=1s med=1s max=1s p(90)=1s p(95)=1s\riterations.....................: 10 0.998173/s\rvus............................: 1 min=1 max=1\rvus_max........................: 1 min=1 max=1\rrunning (10.0s), 0/1 VUs, 10 complete and 0 interrupted iterations\rdefault ✓ [======================================] 1 VUs 10s "
},
{
	"uri": "//localhost:1313/3-pipeline/",
	"title": "Setting Up the CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": "Diagram This diagram illustrates the automated CI/CD process for a web application using the MERN stack (MongoDB, Express.js, React.js, Node.js). This process ensures that the source code is continuously and efficiently built, tested, scanned for security, and deployed.\nPush Code (User to GitLab):\nDeveloper pushes the source code of the MERN stack application to the GitLab repository. This action triggers the CI/CD process. CI/CD Process (GitLab CI/CD):\nCommit: When the source code is pushed, a commit is created in the GitLab repository.\nThe GitLab CI/CD pipeline starts and includes several jobs performed by runners.\nBuild Job (GitLab Runner):\nBuild Frontend (React.js): GitLab Runner builds the frontend application using React.js, including installing dependencies and generating the necessary static files.\nBuild Backend (Node.js and Express.js): Similarly, the backend is built using Node.js and Express.js, ensuring all dependencies are installed and the source code is compiled if needed.\nBuild Docker Image: The entire MERN stack application is packaged into a Docker image for easy deployment and management.\nImage Scanning (Docker and Snyk):\nThe Docker image is scanned for security vulnerabilities using tools like Snyk.\nSend Report (to Telegram): The security scan results are sent via Telegram to notify the development team of the security status of the image.\nDeploy Jobs (GitLab Runner):\nIf the build and security scan processes are successful, the next step is deploying the application. Deploy Frontend and Backend: GitLab Runner deploys the frontend (React.js) and backend (Node.js and Express.js) to the production or staging environment. Image Management (Portus):\nPull Image (Portus): Docker image is managed through Portus, where the image is pulled from this registry.\nPush Image (Portus): After management, the image is pushed to Harbor for storage and additional security scans if needed.\nSecurity Scanning (Arachni):\nThe deployed application is scanned for security vulnerabilities using Arachni to detect flaws in the web application. Performance Testing (k6):\nAfter ensuring security, performance testing is conducted using k6 to ensure the application performs well under high load.\nSend Report: The performance testing results are sent via Telegram to notify the development and operations teams.\nContents Setting Up GitLab Runner Build and Push Docker Image Security Scan and Performance Test Send Report to Telegram "
},
{
	"uri": "//localhost:1313/2-preparation/2.4-database/",
	"title": "Database Server",
	"tags": [],
	"description": "",
	"content": "Install MongoDB Create an EC2 Instance with the following configuration:\nRefer to section 2.2 for the process of creating an EC2 instance.\nAfter successful creation, connect to the EC2 instance and create a Bash Script file to install MongoDB.\n#!/bin/bash\rsudo apt-get install gnupg curl\rcurl -fsSL https://www.mongodb.org/static/pgp/server-7.0.asc | \\\rsudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg \\\r--dearmor\recho \u0026#34;deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse\u0026#34; | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list\rsudo apt-get update\rsudo apt-get install -y mongodb-org\recho \u0026#34;mongodb-org hold\u0026#34; | sudo dpkg --set-selections\recho \u0026#34;mongodb-org-database hold\u0026#34; | sudo dpkg --set-selections\recho \u0026#34;mongodb-org-server hold\u0026#34; | sudo dpkg --set-selections\recho \u0026#34;mongodb-mongosh hold\u0026#34; | sudo dpkg --set-selections\recho \u0026#34;mongodb-org-mongos hold\u0026#34; | sudo dpkg --set-selections\recho \u0026#34;mongodb-org-tools hold\u0026#34; | sudo dpkg --set-selections Run the Bash Script by executing the following command:\nsh \u0026lt;name-file\u0026gt;.sh After a successful installation, start MongoDB Community Edition with:\nsudo systemctl start mongod Check if MongoDB has started successfully with:\nsudo systemctl status mongod You can use the option to ensure MongoDB starts after system reboot with:\nsudo systemctl enable mongod Configuring MongoDB Access the file /etc/mongod.conf to change the IP address range that MongoDB listens to and accepts connections.\nChange from bindIp: 127.0.0.1 to bindIp: 0.0.0.0\n127.0.0.1 (localhost): This is the loopback address of the local machine (localhost). If bindIp is set to 127.0.0.1, MongoDB will only accept connections from the machine where MongoDB is running. Connections from outside (from other computers or networks) will be denied.\n0.0.0.0: When bindIp is set to 0.0.0.0, MongoDB will listen on all IP addresses of the server. This means MongoDB will accept connections from any IP, including local and external machines on the network.\nThis allows us to access MongoDB from a local machine to the virtual machine where MongoDB is installed.\nAfter making the changes, restart MongoDB with:\nsudo systemctl restart mongod Create a Firewall Rule to open the MongoDB Port on the EC2 Instance.\nGo to Instance -\u0026gt; Security. Select the Security Group associated with the Instance.\nSelect Edit Inbound Rules.\nClick Add Rule and configure it as follows:\n27017 is the port used for MongoDB.\nOpening port 27017 to the entire internet (0.0.0.0/0) can create a high-security risk. If possible, restrict access by allowing only trusted IP addresses or ranges.\nConnecting MongoDB Compass to MongoDB on EC2 You can install MongoDB Compass from the following link:\nMongoDB Compass This is the main interface of MongoDB Compass.\nIn the EC2 Instance, we have the Public IPv4 address and Public IPv4 DNS, which we can use to access the database.\nProceed to connect to the database via MongoDB Compass.\nChange localhost to the Public IP address of the Instance and connect:\nAfter a successful connection, you will have a database similar to the one on the server:\nYou can check the database on EC2 with the following command:\nmongosh # Truy cập vào DB show dbs # Show danh sách DB Thus, we have successfully installed the Database Server.\n"
},
{
	"uri": "//localhost:1313/4-deployk8s/",
	"title": "Deploying the Project on Kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/3-pipeline/3.4-send-report/",
	"title": "Send Report to Telegram",
	"tags": [],
	"description": "",
	"content": "Preparation To send reports to Telegram, you need to create a Telegram account.\nAfter successfully creating an account, search for BotFather to create a Bot.\nAfter starting, create a new Bot by entering /newbot.\nOnce you complete the requirements, you will receive a Bot that can be accessed via a link and a Token.\nTo allow the Bot to send notifications, create a Group and add the Bot to it.\nYou need to know the Group ID to send messages, so add the Bot RawDataBot to get the ID.\nYou can test sending a message via the server with the following command:\ncurl -X POST \u0026#34;https://api.telegram.org/bot\u0026lt;Bot_Token\u0026gt;/sendMessage\u0026#34; -d \u0026#34;chat_id=\u0026lt;chat_id\u0026gt;\u0026#34; -d \u0026#34;text=test\u0026#34; curl -X POST \u0026#34;https://api.telegram.org/bot7zxsdfsdf:asskafiscaisdasca/sendMessage\u0026#34; -d \u0026#34;chat_id=-22asdcasd\u0026#34; -d \u0026#34;text=test\u0026#34; Send Report Stage We will add a Stage to send the Report immediately after completing the Tests.\nThis Stage will have 2 Jobs.\nThe send report from build server job will send 2 report files Code Security Scan and Image Scan generated before deploying the project.\nThe send report from dev server job, similar to the previous job, will send report files after deploying the project.\nsend report from build server: stage: send report variables: GIT_STRATEGY: none script: - curl -F \u0026#34;chat_id=${TELE_GROUP_CHAT_ID}\u0026#34; -F \u0026#39;media=[{\u0026#34;type\u0026#34;:\u0026#34;document\u0026#34;,\u0026#34;media\u0026#34;:\u0026#34;attach://file1\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;document\u0026#34;,\u0026#34;media\u0026#34;:\u0026#34;attach://file2\u0026#34;}]\u0026#39; -F \u0026#34;file1=@$(pwd)/${SNYK_SECURITY_SCAN_REPORT}.html\u0026#34; -F \u0026#34;file2=@$(pwd)/${TRIVYFS_SCAN_IMAGE_REPORT}.html\u0026#34; \u0026#34;https://api.telegram.org/bot${API_BOT}/sendMediaGroup\u0026#34; tags: - wineapp-build-shell only: - tags send report from dev server: stage: send report variables: GIT_STRATEGY: none script: - curl -F \u0026#34;chat_id=${TELE_GROUP_CHAT_ID}\u0026#34; -F \u0026#39;media=[{\u0026#34;type\u0026#34;:\u0026#34;document\u0026#34;,\u0026#34;media\u0026#34;:\u0026#34;attach://file1\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;document\u0026#34;,\u0026#34;media\u0026#34;:\u0026#34;attach://file2\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;document\u0026#34;,\u0026#34;media\u0026#34;:\u0026#34;attach://file3\u0026#34;}]\u0026#39; -F \u0026#34;file1=@$(pwd)/${ARACHNI_WEBSITE_REPORT}.html.zip\u0026#34; -F \u0026#34;file2=@$(pwd)/${K6_PERFORMANCE_TEST_REPORT}.html\u0026#34; -F \u0026#34;file3=@$(pwd)/${K6_PERFORMANCE_TEST_REPORT}.csv\u0026#34; \u0026#34;https://api.telegram.org/bot${API_BOT}/sendMediaGroup\u0026#34; tags: - wineapp-dev-shell only: - tags After running the pipeline, the Bot will send the report files from the previous Stages.\n"
},
{
	"uri": "//localhost:1313/5-gitops/",
	"title": "GitOps",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/2-preparation/2.5-snyk/",
	"title": "Source Code Security - Snyk",
	"tags": [],
	"description": "",
	"content": "Installing NodeJS and npm sudo apt install npm -y Check the version:\ntranvi0910@deployment-server:~$ node -v v18.20.4 tranvi0910@deployment-server:~$ npm -v v10.7.0 Installing Snyk with npm Install Snyk on the Build Server:\nnpm install snyk -g # Format HTML npm install snyk-to-html -g root@build-server:~# npm install snyk -g added 36 packages in 56s 12 packages are looking for funding run `npm fund` for details root@development-server:~# npm install snyk-to-html -g added 23 packages in 5s 1 package is looking for funding run `npm fund` for details Log in to the official Snyk website and proceed with authentication.\nLink Snyk Get your API Token from your account:\nRun the following command on the Development Server to authenticate Snyk:\nsnyk auth ab089484-2b45-4f10-b991-xxxxxxxxxxx root@build-server:~# snyk auth ab089484-2b45-4f10-b991-d101f237fecb Executable doesn\u0026#39;t exist, trying to download. Downloading from \u0026#39;https://static.snyk.io/cli/v1.1292.1/snyk-linux\u0026#39; to \u0026#39;/usr/lib/node_modules/snyk/wrapper_dist/snyk-linux\u0026#39; Shasums: - actual: xxxxxxxxxxxxxxx - expected: xxxxxxxxxxxxxxx Downloaded successfull! Your account has been authenticated. Snyk is now ready to be used. Navigate to the project directory and proceed with testing:\ncd /projects/wineapp/wineapp-frontend\rsnyk test You can view detailed issues using the following command:\nsnyk monit You can test and save the results to an HTML file:\nsnyk test --json | snyk-to-html -o \u0026lt;name_file\u0026gt;.html Thus, Snyk has been installed and configured successfully.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.6-trivy/",
	"title": "Trivy Security Scan Image",
	"tags": [],
	"description": "",
	"content": "Installing Docker and Docker Compose Create a Bash Script file to install Docker and Docker Compose.\n#!/bin/bash sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt update -y sudo apt install docker-ce -y sudo systemctl start docker sudo systemctl enable docker sudo curl -L \u0026#34;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker -v docker-compose -v Run the script with the following command:\nsh \u0026lt;name-file\u0026gt;.sh Docker and Docker Compose are successfully installed.\nInstalling Trivy via Docker Image Trivy can be used in the following ways:\n# Install Trivy\rbrew install aquasecurity/trivy/trivy\r# Scan a Docker image\rtrivy image your-docker-image\r# Scan a filesystem\rtrivy fs /path/to/your/filesystem\r# Scan source code\rtrivy repo https://github.com/your/repo In this workshop, we will install Trivy via Docker Image.\nYou can perform a source code scan while pulling the Trivy Image from Docker Hub:\ndocker run aquasec/trivy fs . You can generate security scan reports with Trivy.\nTrivy Report Formats $ trivy image --format template --template \u0026#34;@contrib/html.tpl\u0026#34; -o report.html golang:1.12-alpine "
},
{
	"uri": "//localhost:1313/2-preparation/2.7-arachni/",
	"title": "Web Application Security Scan",
	"tags": [],
	"description": "",
	"content": "Web Application Security Scan with Arachni Once the project is successfully deployed, you can proceed with a web security scan.\nInstall Arachni on the Development Server. Since the project is deployed on this server, we will perform the test on this server.\nCreate a user for Arachni:\nadduser arachni Download and extract the Arachni installation file:\nwget https://github.com/Arachni/arachni/releases/download/v1.5.1/arachni-1.5.1-0.5.12-linux-x86_64.tar.gz\rtar -xvf arachni-1.5.1-0.5.12-linux-x86_64.tar.gz Navigate to the extracted directory.\nThe bin directory contains the executable commands, which you can run through this directory.\nYou can run the following command to scan a deployed web page:\nbin/arachni --output-verbose --scope-include-subdomains http://\u0026lt;your-ip\u0026gt;:\u0026lt;port\u0026gt; --report-save-path=/tmp/\u0026lt;name-file\u0026gt;.afr http://\u0026lt;your-ip\u0026gt;:\u0026lt;port\u0026gt;: This is the address of the web application.\nThe scan results will be saved in the \u0026lt;name-file\u0026gt;.afr file.\nArachni Framework Report (.afr) is the format of the report file.\nYou can convert it to an HTML file using the command:\nbin/arachni_reporter /tmp/wineapp-frontend.afr --reporter=html:outfile=\u0026lt;name-file\u0026gt;.html.zip arachni@development-server:~/arachni-1.5.1-0.5.12$ bin/arachni_reporter /tmp/wineapp-frontend.afr --reporter=html:outfile=wineapp-backend.html.zip\rArachni - Web Application Security Scanner Framework v1.5.1\rAuthor: Tasos \u0026#34;Zapotek\u0026#34; Laskos \u0026lt;tasos.laskos@arachni-scanner.com\u0026gt;\r(With the support of the community and the Arachni Team.)\rWebsite: http://arachni-scanner.com\rDocumentation: http://arachni-scanner.com/wiki\r[*] HTML: Creating HTML report...\r[*] HTML: Saved in \u0026#39;wineapp-backend.html.zip\u0026#39;.\rarachni@development-server:~/arachni-1.5.1-0.5.12$ ls -l\rtotal 904\rdrwxrwxr-x 2 arachni arachni 4096 Mar 29 2017 bin\r-rw-rw-r-- 1 arachni arachni 6253 Mar 29 2017 LICENSE\r-rw-rw-r-- 1 arachni arachni 893570 Jul 21 15:24 wineapp-backend.html.zip \u0026lt;-----------------------------\r-rw-rw-r-- 1 arachni arachni 1929 Mar 29 2017 README\rdrwxrwxr-x 7 arachni arachni 4096 Mar 29 2017 system\r-rw-rw-r-- 1 arachni arachni 2078 Mar 29 2017 TROUBLESHOOTING\r-rw-rw-r-- 1 arachni arachni 13 Mar 29 2017 VERSION Creating a Docker Image for Arachni ## Tools: Arachni ## OS: Ubuntu ## Version: v1 FROM ubuntu:latest RUN apt update -y \u0026amp;\u0026amp; \\ apt install -y wget tar \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* RUN wget https://github.com/Arachni/arachni/releases/download/v1.5.1/arachni-1.5.1-0.5.12-linux-x86_64.tar.gz \u0026amp;\u0026amp; \\ tar -xvf arachni-1.5.1-0.5.12-linux-x86_64.tar.gz \u0026amp;\u0026amp; \\ rm arachni-1.5.1-0.5.12-linux-x86_64.tar.gz WORKDIR /arachni-1.5.1-0.5.12 CMD [\u0026#34;bin/arachni\u0026#34;] Build the image:\ndocker build -t tranvi0910/arachni:v1.5.1-0.5.12 . Next, log in and push the image to Dockerhub. During the CI/CD process, you can pull the image and perform the test.\ndocker login\rdocker push tranvi0910/arachni:v1.5.1-0.5.12 The setup and installation of Arachni are complete.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.8-k6/",
	"title": "Performance Testing - k6",
	"tags": [],
	"description": "",
	"content": "Installing k6 Create a shell script to install k6 on the Build Server.\n#!/bin/bash sudo gpg -k sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69 echo \u0026#34;deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\u0026#34; | sudo tee /etc/apt/sources.list.d/k6.list sudo apt-get update sudo apt-get install k6 Run the script:\nsh install-k6.sh Types of Performance Testing Before using k6, let’s understand the definitions and differences between these types of performance testing.\nLoad Testing: This process tests software by applying a high load to measure and evaluate factors such as response time, system resource consumption, and system stability under high load. Smoke Testing: This testing determines whether the software version can launch and operate normally with the most basic functions.\nIt is an initial test to decide if the software is stable enough for more detailed testing.\nLoad Testing (for Performance): Focuses on evaluating system performance under specific load conditions to ensure it meets performance requirements such as response time and request handling within acceptable limits. Stress Testing: This testing identifies the limits of the system by applying a higher load than expected, increasing and decreasing the number of users to test.\nThe goal is to find the breaking point of the system, allowing for optimization and preparation for sudden high loads.\nSpike Testing: A specific type of Stress Testing, this test simulates sudden load increases over a short period to assess the system’s ability to handle sudden load fluctuations. Soak/Endurance Testing: This testing evaluates system performance under a load over a long period to identify potential long-term performance issues like memory leaks or performance degradation over time. Setting Up k6 Test For example, create a load-test.js file and perform the test.\nimport http from \u0026#39;k6/http\u0026#39;; import { check, sleep } from \u0026#39;k6\u0026#39;; export let options = { vus: 100, duration: \u0026#39;10s\u0026#39;, thresholds: { http_req_duration: [\u0026#39;p(95)\u0026lt;500\u0026#39;] // 95% request dưới 500ms } }; export default function () { const BASE_URL = \u0026#39;http://192.168.181.104:3000/\u0026#39;; let res = http.get(BASE_URL); check(res, { \u0026#39;status was 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); sleep(1); } Output:\nroot@build-server:/tools/k6# k6 run load-test.js\r/\\ |‾‾| /‾‾/ /‾‾/\r/\\ / \\ | |/ / / /\r/ \\/ \\ | ( / ‾‾\\\r/ \\ | |\\ \\ | (‾) |\r/ __________ \\ |__| \\__\\ \\_____/ .io\rexecution: local\rscript: load-test.js\routput: -\rscenarios: (100.00%) 1 scenario, 100 max VUs, 40s max duration (incl. graceful stop):\r* default: 100 looping VUs for 10s (gracefulStop: 30s)\r✓ status was 200\rchecks.........................: 100.00% ✓ 811 ✗ 0\rdata_received..................: 781 kB 71 kB/s\rdata_sent......................: 70 kB 6.4 kB/s\rhttp_req_blocked...............: avg=14.71ms min=30.3µs med=44.3µs max=433.35ms p(90)=64.81ms p(95)=105.95ms\rhttp_req_connecting............: avg=10.95ms min=0s med=0s max=188.22ms p(90)=52.37ms p(95)=95.06ms\r✓ http_req_duration..............: avg=202.57ms min=2.04ms med=200.53ms max=508.74ms p(90)=337.88ms p(95)=384.15ms\r{ expected_response:true }...: avg=202.57ms min=2.04ms med=200.53ms max=508.74ms p(90)=337.88ms p(95)=384.15ms\rhttp_req_failed................: 0.00% ✓ 0 ✗ 811\rhttp_req_receiving.............: avg=1.67ms min=85.7µs med=150.2µs max=120.63ms p(90)=1.18ms p(95)=4.52ms\rhttp_req_sending...............: avg=31.14ms min=40µs med=69.8µs max=354.27ms p(90)=117.14ms p(95)=148.13ms\rhttp_req_tls_handshaking.......: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s\rhttp_req_waiting...............: avg=169.76ms min=921.41µs med=151.78ms max=440.52ms p(90)=300.11ms p(95)=334.18ms\rhttp_reqs......................: 811 73.898412/s\riteration_duration.............: avg=1.29s min=1s med=1.29s max=1.68s p(90)=1.46s p(95)=1.5s\riterations.....................: 811 73.898412/s\rvus............................: 2 min=2 max=100\rvus_max........................: 100 min=100 max=100\rrunning (11.0s), 000/100 VUs, 811 complete and 0 interrupted iterations\rdefault ✓ [======================================] 100 VUs 10s data_received:\nThe total amount of data received from the server through HTTP requests during the test. data_sent:\nThe total amount of data sent from the client to the server through HTTP requests during the test. http_req_blocked:\nThe time blocked before the HTTP request is sent (possibly due to bandwidth limits, resource constraints, etc.).\nIndicates how long the request had to wait before being processed.\nhttp_req_connecting:\nThe time to connect to the server after sending the request. http_req_duration:\nThe total time to complete the HTTP request, from start to finish, including the response. http_req_failed:\nThe number of failed HTTP requests (could be due to network errors, server errors, etc.). http_req_receiving:\nThe time to receive data from the server after the HTTP request has been sent. http_req_sending:\nThe time to send data to the server (client -\u0026gt; server). http_req_tls_handshaking:\nThe time to establish a secure connection (SSL)\nTime taken for TLS handshake for HTTPS connections.\nhttp_req_waiting:\nThe time to wait for a response from the server after sending the HTTP request. http_reqs:\nThe total number of HTTP requests made. iteration_duration:\nThe time to perform one iteration of the test script. iterations:\nThe total number of iterations performed in the test script. vus:\nThe number of virtual users currently performing the test. vus_max:\nThe maximum number of virtual users during the test. Thus, we have successfully installed k6 and performed a basic test.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]